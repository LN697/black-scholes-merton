# Technical Architecture Overview

This document provides a comprehensive technical overview of the Black-Scholes-Merton pricing toolkit, detailing the mathematical models, numerical methods, and software architecture.

## ğŸ—ï¸ System Architecture

### Design Principles
- **Modularity**: Each pricing method is self-contained with clean interfaces
- **Performance**: Optimized algorithms with minimal runtime overhead
- **Extensibility**: Plugin architecture for new models and payoffs
- **Reliability**: Comprehensive testing and numerical validation
- **Portability**: Cross-platform C++17 with minimal dependencies

### Core Components Hierarchy
```
Application Layer (main.cpp)
    â”œâ”€â”€ Analytics Module (analytic_bs.hpp)
    â”œâ”€â”€ Monte Carlo Engine (monte_carlo_gbm.hpp)
    â”œâ”€â”€ PDE Solvers (pde_cn*.hpp)
    â”œâ”€â”€ SLV Framework (slv.hpp)
    â””â”€â”€ Utilities Layer (math_utils.hpp, stats.hpp)
```

### Memory and Performance Architecture
- **Stack-allocated structures**: Minimal heap allocations for hot paths
- **SIMD-friendly algorithms**: Vectorizable loops and data layouts
- **Cache-conscious design**: Sequential memory access patterns
- **Optional parallelization**: OpenMP for embarrassingly parallel workloads

## ğŸ“Š Mathematical Models and Algorithms

### 1. Black-Scholes Analytical Engine
**File**: `include/analytic_bs.hpp`, `src/analytic_bs.cpp`

**Mathematical Model**:
```
dS_t = rS_t dt + ÏƒS_t dW_t

European Call: C = Sâ‚€N(dâ‚) - Ke^(-rT)N(dâ‚‚)
European Put:  P = Ke^(-rT)N(-dâ‚‚) - Sâ‚€N(-dâ‚)

where:
dâ‚ = [ln(Sâ‚€/K) + (r + ÏƒÂ²/2)T] / (ÏƒâˆšT)
dâ‚‚ = dâ‚ - ÏƒâˆšT
```

**Implementation Features**:
- Robust numerical evaluation with edge case handling
- Optimized normal CDF computation using error functions
- Intrinsic value fallback for degenerate cases (Ïƒ â‰¤ 0, T â‰¤ 0)

**Complexity**: O(1) per evaluation

### 2. Monte Carlo GBM Engine
**File**: `include/monte_carlo_gbm.hpp`, `src/monte_carlo_gbm.cpp`

**Core Algorithm**:
```cpp
// Geometric Brownian Motion simulation
S_t = Sâ‚€ * exp((r - ÏƒÂ²/2)T + ÏƒâˆšT * Z)
where Z ~ N(0,1)
```

**Variance Reduction Techniques**:

#### Antithetic Variates
```cpp
Path 1: Sâ‚ = Sâ‚€ * exp((r - ÏƒÂ²/2)T + ÏƒâˆšT * Z)
Path 2: Sâ‚‚ = Sâ‚€ * exp((r - ÏƒÂ²/2)T - ÏƒâˆšT * Z)
Estimate: (Payoff(Sâ‚) + Payoff(Sâ‚‚)) / 2
```
- **Variance Reduction**: ~50% for path-dependent options
- **Computational Cost**: Negligible additional overhead

#### Control Variates
Two-pass implementation with optimal beta estimation:
```cpp
// Pass 1: Estimate Î² = Cov(Payoff, Control) / Var(Control)
// Pass 2: Adjusted_Payoff = Payoff - Î²(Control - E[Control])
```
- **Control Variable**: Terminal spot price vs analytical expectation
- **Variance Reduction**: 60-80% for vanilla options

#### Quasi-Monte Carlo (Halton Sequences)
```cpp
// Halton sequence generation for bases 2 and 3
H_n^(b) = Î£(d_i * b^(-i-1))  where n = Î£(d_i * b^i)
```
- **Convergence Rate**: O(log(N)Â²/N) vs O(1/âˆšN) for standard MC
- **Implementation**: Scrambled Halton with random shifts for better uniformity

#### Greeks Calculation
**Pathwise Estimator (Delta)**:
```cpp
Î´ = âˆ‚Payoff/âˆ‚Sâ‚€ = (âˆ‚Payoff/âˆ‚S_T) * (S_T/Sâ‚€)
```

**Likelihood Ratio Estimator (Vega)**:
```cpp
Î½ = Payoff * âˆ‚ln(f)/âˆ‚Ïƒ = Payoff * [(ZÂ²-1)/Ïƒ - ZâˆšT]
where f is the transition density
```

**Complexity**: O(N) for N simulation paths
**Parallelization**: OpenMP reduction over independent path batches

### 3. PDE Finite Difference Solvers
**Files**: `include/pde_cn.hpp`, `include/pde_cn_american.hpp`

**Mathematical Framework**:
```
âˆ‚V/âˆ‚t + (1/2)ÏƒÂ²SÂ²âˆ‚Â²V/âˆ‚SÂ² + rSâˆ‚V/âˆ‚S - rV = 0

Boundary Conditions:
- S = 0: V(0,t) = max(K*e^(-r(T-t)) - 0, 0) for puts
- S â†’ âˆ: V(S,t) â‰ˆ S - K*e^(-r(T-t)) for calls
- t = T: V(S,T) = Payoff(S)
```

#### Crank-Nicolson Discretization
**Spatial Grid**: Uniform spacing in S-direction
**Time Stepping**: Implicit-explicit Î¸-scheme with Î¸ = 0.5

**Discretized Equation**:
```
[I - (Î”t/2)L] V^(n+1) = [I + (Î”t/2)L] V^n
```

**Tri-diagonal System Solution**:
- **Thomas Algorithm**: O(N) complexity for banded matrix inversion
- **Stability**: Unconditionally stable for Î¸ â‰¥ 0.5
- **Accuracy**: O(Î”tÂ², Î”SÂ²) truncation error

#### American Option Enhancement (Projected Crank-Nicolson)
**Early Exercise Constraint**: V(S,t) â‰¥ Payoff(S) âˆ€t

**Algorithmic Implementation**:
```cpp
for each time step:
    1. Solve European step: V_temp = CN_step(V_old)
    2. Apply constraint: V_new = max(V_temp, Payoff)
    3. Update boundary conditions
```

**Convergence**: Monotonic convergence to optimal stopping boundary

### 4. Stochastic Local Volatility (SLV) Framework
**File**: `include/slv.hpp`, `src/slv.cpp`

**Mathematical Model**:
```
dS_t = rS_t dt + L(S,t)âˆšv_t Ïƒ_local(S,t) S_t dW_t^S
dv_t = Îº(Î¸ - v_t)dt + Î¾âˆšv_t dW_t^v

âŸ¨dW_t^S, dW_t^vâŸ© = Ï dt
```

**Components**:
1. **Heston Variance Process**: Andersen QE discretization scheme
2. **Local Volatility Function**: Pluggable interface (CEV, Smile, etc.)
3. **Leverage Function**: L(S,t) for calibration to market data

#### Andersen QE Discretization
**Variance Evolution**:
```cpp
if Ïˆ â‰¤ Ïˆ_critical:
    // Central chi-squared approximation
    v_{n+1} = a(b + ZÂ²)
else:
    // Quadratic exponential scheme  
    v_{n+1} = a(b + Z)Â² for Z > Ïˆâ»Â¹, else 0
```

**Advantages**:
- **Positivity**: Ensures v_t â‰¥ 0 always
- **Accuracy**: Superior to Euler or Milstein schemes
- **Efficiency**: O(1) per step with pre-computed coefficients

#### Local Volatility Models

**CEV (Constant Elasticity of Variance)**:
```cpp
Ïƒ_local(S,t) = Ïƒâ‚€ * (S/Sâ‚€)^(Î²-1)
```

**Smile Model** (Parametric Local Volatility):
```cpp
Ïƒ_local(S,t) = Ïƒ_ATM * (1 + Î± * log(S/K) + Î² * logÂ²(S/K)) * exp(-Î³*t)
```

**Interface Design**:
```cpp
using LocalVolFn = std::function<double(double S, double t)>;
```

### 5. Longstaff-Schwartz Algorithm (LSM)
**File**: `include/lsm.hpp`, `src/lsm.cpp`

**American Put Pricing via Regression**:

**Algorithm Steps**:
1. **Forward Simulation**: Generate all price paths to maturity
2. **Backward Induction**: At each exercise date:
   - **Regression**: Fit continuation value on in-the-money paths
   - **Decision**: Exercise if immediate payoff > continuation value
   - **Update**: Cash flows and optimal exercise strategy

**Basis Functions**:
```cpp
Î¦(S) = [1, S/K, (S/K)Â², ..., (S/K)â¿]
```

**Regression Equation**:
```cpp
Continuation(S) = Î£áµ¢ Î±áµ¢ Î¦áµ¢(S)
where Î± = (Î¦áµ€Î¦)â»Â¹Î¦áµ€Y
```

**Complexity**: O(NÃ—MÃ—P) for N paths, M time steps, P basis functions

### Utilities
- File: `include/math_utils.hpp`, `include/stats.hpp`
- Contains: normal CDF, RNG, correlated Gaussians, Halton sequence with shifts, Boxâ€“Muller, stateless hash RNG for indexed sampling, and result structs with standard errors.

## SLV Calibration Notes

Goal: find leverage L(S,t) so the model-implied local variance matches a target Dupire surface Ïƒ_target(S,t).

Iterative outline (PDE or particle MC):
1. Initialize Lâ‚€(S,t) = 1 (or from a heuristic).
2. Under current L, price a thin grid of options (or estimate local variance) to get Ïƒ_model(S,t).
3. Update: L_{k+1}(S,t) = L_k(S,t) Â· Ïƒ_target(S,t) / max(Ïƒ_model(S,t), Îµ).
4. Repeat until convergence on a mesh in (S,t).

Code scaffolding: `include/dupire.hpp` (surface representation) and `include/slv_calibration.hpp` (grid and loop skeleton) are in place; the Ïƒ_model estimator is the next implementation step.

## How to Build and Run

Windows (MinGW) and Linux are supported via GNU Make:

```sh
make
make test
make clean
```

Toggle OpenMP with `OMP=1` (requires compiler support):

```sh
make OMP=1
```

## References and Concepts
- Blackâ€“Scholes (1973); Crankâ€“Nicolson finite differences; Thomas algorithm for tri-diagonal systems.
- Control variates, antithetic sampling; Halton quasi-random sequences; Boxâ€“Muller transform.
- Heston (1993) and Andersen QE (2008) discretization.
- Dupire (1994) local volatility; SLV leverage calibration via fixed-point iteration.
